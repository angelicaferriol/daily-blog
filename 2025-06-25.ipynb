{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "164be147",
   "metadata": {},
   "source": [
    "# Daily Blog #56 - Feature Scaling & Normalization\n",
    "### June 25, 2025\n",
    "\n",
    "### Why scaling matters?\n",
    "\n",
    "Imagine you have a dataset with two features:\n",
    "\n",
    "* Age in years (0–100)\n",
    "* Annual income (\\$0–1,000,000)\n",
    "\n",
    "If you use these raw features in a distance-based algorithm (e.g. k-NN), **income will completely dominate** the distance calculation.\n",
    "That means the model becomes blind to Age, because one feature is on a vastly larger scale.\n",
    "\n",
    "\n",
    "### Scaling Techniques\n",
    "\n",
    "Here are the most common methods:\n",
    "\n",
    "#### **1. Min-Max Scaling (Normalization)**\n",
    "\n",
    "Brings all features into the range \\[0, 1]:\n",
    "\n",
    "$$\n",
    "x_{scaled} = \\frac{x - \\min(x)}{\\max(x)-\\min(x)}\n",
    "$$\n",
    "\n",
    "#### **2. Standardization (Z-score normalization)**\n",
    "\n",
    "Centers data around mean 0 with unit variance:\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "#### **3. RobustScaler (using median & IQR)**\n",
    "\n",
    "Less affected by outliers — often used in messy real-world data.\n",
    "\n",
    "### Example in Python\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Dummy data\n",
    "X = np.array([[25, 50000], \n",
    "              [40, 80000], \n",
    "              [60, 120000]])\n",
    "\n",
    "# Min-Max Scaling\n",
    "minmax = MinMaxScaler()\n",
    "X_minmax = minmax.fit_transform(X)\n",
    "\n",
    "# Z-score normalization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Min-Max scaled:\\n\", X_minmax)\n",
    "print(\"Standardized:\\n\", X_scaled)\n",
    "```\n",
    "\n",
    "### When to choose what?\n",
    "- **Min-Max Scaling** — use when you want features on a fixed range \\[0,1] or \\[-1,1], especially for neural networks.\n",
    "- **Standardization** — when data is approximately normally distributed or you want to preserve outliers as extreme z-scores.\n",
    "- **RobustScaler** — when you have extreme outliers.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

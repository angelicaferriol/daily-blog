{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f46f22",
   "metadata": {},
   "source": [
    "# Daily Blog #61 - Underwater Image Preprocessing and Classification\n",
    "### June 30, 2025 \n",
    "\n",
    "---\n",
    "\n",
    "## PART 1: WHY UNDERWATER IMAGES ARE CHALLENGING\n",
    "\n",
    "### Underwater image issues:\n",
    "\n",
    "1. **Color Distortion** – Red is absorbed first, then green, blue lasts longest.\n",
    "2. **Low Contrast** – Due to light scattering and absorption.\n",
    "3. **Noise & Haze** – Due to floating particles (turbidity).\n",
    "4. **Blur & Motion Artifacts** – Caused by currents or moving creatures.\n",
    "5. **Lighting Non-uniformity** – Natural light varies drastically with depth and turbidity.\n",
    "\n",
    "This makes underwater image **preprocessing mandatory** before any classification task.\n",
    "\n",
    "---\n",
    "\n",
    "## PART 2: UNDERWATER IMAGE PREPROCESSING\n",
    "\n",
    "### 2.1 Color Correction\n",
    "\n",
    "To restore the original colors and improve visibility:\n",
    "\n",
    "* **White Balance Algorithms**\n",
    "\n",
    "  * **Gray World Assumption** – Assumes average color in the scene should be gray.\n",
    "* **Histogram Equalization**\n",
    "\n",
    "  * Stretch contrast over intensity range (CLAHE is often better for localized contrast).\n",
    "* **Retinex-based Algorithms**\n",
    "\n",
    "  * Simulates human perception to adjust illumination (Single-Scale/Multiscale Retinex).\n",
    "* **Physics-Based Models**\n",
    "\n",
    "  * Use light attenuation models (e.g., **Diving Bell Model** or **Water Type-Specific Models**).\n",
    "\n",
    "### 2.2 Dehazing and Contrast Enhancement\n",
    "\n",
    "* **Dark Channel Prior (DCP)** – Assumes at least one color channel has low intensity; used for haze removal.\n",
    "* **Fusion-based Methods**\n",
    "\n",
    "  * Combine different enhanced versions of an image using weight maps.\n",
    "* **Anisotropic Diffusion** – Reduces noise without removing edges.\n",
    "\n",
    "### 2.3 Image Denoising\n",
    "\n",
    "* **Gaussian/Median Filters** – Basic, but can blur important features.\n",
    "* **Non-local Means Denoising**\n",
    "* **Wavelet-based Denoising**\n",
    "* **Deep Learning Methods** (like DnCNN) – Learn to separate noise from signal.\n",
    "\n",
    "### 2.4 Super-Resolution (Optional)\n",
    "\n",
    "For extremely low-quality images, apply:\n",
    "\n",
    "* **SRGAN (Super Resolution GAN)**\n",
    "* **ESRGAN** – Enhanced SRGAN\n",
    "  To improve resolution and detail before classification.\n",
    "\n",
    "---\n",
    "\n",
    "## PART 3: UNDERWATER IMAGE CLASSIFICATION\n",
    "\n",
    "### 3.1 Traditional Approaches (Feature-based)\n",
    "\n",
    "1. **Feature Extraction**\n",
    "\n",
    "   * **Color Histograms**\n",
    "   * **Texture** (LBP, GLCM)\n",
    "   * **Shape Descriptors**\n",
    "2. **Classifiers**\n",
    "\n",
    "   * SVM (Support Vector Machine)\n",
    "   * k-NN (k Nearest Neighbors)\n",
    "   * Random Forest\n",
    "   * Decision Trees\n",
    "\n",
    "Effective for simple classification (e.g., coral vs. rock vs. sand).\n",
    "\n",
    "### 3.2 Deep Learning-Based Methods (Data-driven)\n",
    "\n",
    "#### Architecture Types:\n",
    "\n",
    "##### 1. **CNN (Convolutional Neural Networks)**\n",
    "\n",
    "* Best for general image classification.\n",
    "* Examples:\n",
    "\n",
    "  * VGG16 / ResNet50\n",
    "  * EfficientNet for resource efficiency\n",
    "\n",
    "##### 2. **Transfer Learning**\n",
    "\n",
    "* Pretrained models (ImageNet) fine-tuned on underwater datasets.\n",
    "* Common strategy due to data scarcity.\n",
    "\n",
    "##### 3. **Two-Stream Networks**\n",
    "\n",
    "* One stream processes the original image, another processes enhanced/preprocessed version.\n",
    "\n",
    "##### 4. **Transformer-based Models**\n",
    "\n",
    "* ViTs (Vision Transformers) now being adapted to underwater tasks for broader spatial understanding.\n",
    "\n",
    "### 3.3 Loss Functions (for Training)\n",
    "\n",
    "* **Cross-Entropy Loss** – For multi-class classification.\n",
    "* **Focal Loss** – For imbalanced datasets.\n",
    "* **Dice Loss / IoU Loss** – Often used in segmentation but useful if overlap matters.\n",
    "\n",
    "---\n",
    "\n",
    "## PART 4: UNDERWATER DATASETS FOR CLASSIFICATION\n",
    "\n",
    "* **EILAT Dataset** – Coral reef images.\n",
    "* **RSMAS Coral Dataset** – Over 2000 coral species images.\n",
    "* **UIEB (Underwater Image Enhancement Benchmark)** – For enhancement evaluation.\n",
    "* **Fish4Knowledge** – Real-time video and fish classification dataset.\n",
    "\n",
    "You can also manually label and classify using:\n",
    "\n",
    "* **LabelImg** (bounding boxes)\n",
    "* **Roboflow** or **CVAT** (for segmentation or classification)\n",
    "\n",
    "---\n",
    "\n",
    "## PART 5: PIPELINE SUMMARY (END-TO-END)\n",
    "\n",
    "### Step-by-step:\n",
    "\n",
    "1. **Data Collection**\n",
    "\n",
    "   * Videos/images via ROVs, AUVs, or divers.\n",
    "2. **Preprocessing**\n",
    "\n",
    "   * Color correction (e.g., Retinex, Gray World)\n",
    "   * Dehazing & contrast (DCP, CLAHE)\n",
    "   * Denoising (Non-local Means, DnCNN)\n",
    "   * Optional: Upsampling (ESRGAN)\n",
    "3. **Annotation**\n",
    "\n",
    "   * Manual or semi-automatic labeling.\n",
    "4. **Model Selection**\n",
    "\n",
    "   * Classical (SVM) or Deep (CNN, Transfer Learning)\n",
    "5. **Training & Evaluation**\n",
    "\n",
    "   * Cross-validation, confusion matrix, F1-score\n",
    "6. **Deployment**\n",
    "\n",
    "   * Use ONNX, TensorRT, or TensorFlow Lite for edge deployment on marine robots.\n",
    "\n",
    "---\n",
    "\n",
    "## BONUS: ADVANCED STRATEGIES\n",
    "\n",
    "* **Attention Mechanisms** – Improve model focus on relevant features.\n",
    "* **Multi-task Learning** – Simultaneous classification + segmentation.\n",
    "* **Few-Shot Learning** – Important for rare marine species.\n",
    "\n",
    "---\n",
    "\n",
    "## TOOLS & LIBRARIES\n",
    "\n",
    "* Python, OpenCV, PyTorch, TensorFlow\n",
    "* `imgaug` or `Albumentations` for underwater-specific augmentation\n",
    "* `UnderwaterGAN`, `SeaThru`, `UWCNN` – for enhancement and restoration\n",
    "\n",
    "---\n",
    "\n",
    "## CAUTION\n",
    "\n",
    "* Preprocessing can **distort class-relevant features** if not carefully tuned.\n",
    "* Overfitting is a real threat due to limited underwater labeled data.\n",
    "* Always validate with **diverse lighting/depth conditions**.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
